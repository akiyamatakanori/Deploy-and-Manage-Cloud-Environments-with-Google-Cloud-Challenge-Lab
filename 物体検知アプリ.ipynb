{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3kqarA8FOmVrB+MyZVFCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akiyamatakanori/Deploy-and-Manage-Cloud-Environments-with-Google-Cloud-Challenge-Lab/blob/main/%E7%89%A9%E4%BD%93%E6%A4%9C%E7%9F%A5%E3%82%A2%E3%83%97%E3%83%AA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Object Detection Demo"
      ],
      "metadata": {
        "id": "3SAoUQ4DZnwD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jdW9UANMZm_e",
        "outputId": "fd89e8e8-24f9-4c1f-88f2-dc12119eeb60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 必要なライブラリをインストールしています...\n"
          ]
        }
      ],
      "source": [
        "# ステップ1: 必要なライブラリのインストール\n",
        "print(\"📦 必要なライブラリをインストールしています...\")\n",
        "!pip install -q streamlit opencv-python-headless numpy matplotlib torch torchvision pillow transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ステップ2: アプリケーションファイルの作成\n",
        "print(\"\\n📝 アプリケーションファイルを作成しています...\")\n",
        "\n",
        "app_code = '''\n",
        "import streamlit as st\n",
        "\n",
        "# ページ設定（最初に実行する必要がある）\n",
        "try:\n",
        "    st.set_page_config(\n",
        "        page_title=\"物体検知アプリ\",\n",
        "        page_icon=\"🎯\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"expanded\"\n",
        "    )\n",
        "except:\n",
        "    pass\n",
        "\n",
        "import torch\n",
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# カスタムCSS\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .main { padding: 0rem 1rem; }\n",
        "    .stButton>button {\n",
        "        width: 100%;\n",
        "        background-color: #4CAF50;\n",
        "        color: white;\n",
        "        font-weight: bold;\n",
        "        border-radius: 5px;\n",
        "        border: none;\n",
        "        padding: 0.5rem 1rem;\n",
        "        margin: 0.5rem 0;\n",
        "    }\n",
        "    .stButton>button:hover { background-color: #45a049; }\n",
        "    h1 { color: #2e7d32; text-align: center; padding: 1rem 0; }\n",
        "    h2 { color: #1976d2; border-bottom: 2px solid #1976d2; padding-bottom: 0.5rem; }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# セッション状態の初期化\n",
        "if 'detector' not in st.session_state:\n",
        "    st.session_state.detector = None\n",
        "if 'processed_images' not in st.session_state:\n",
        "    st.session_state.processed_images = []\n",
        "if 'processed_videos' not in st.session_state:\n",
        "    st.session_state.processed_videos = []\n",
        "\n",
        "@st.cache_resource\n",
        "def load_detector(model_name=\"facebook/detr-resnet-50\"):\n",
        "    \"\"\"モデルを読み込む（キャッシュ対応）\"\"\"\n",
        "    try:\n",
        "        processor = DetrImageProcessor.from_pretrained(model_name)\n",
        "        model = DetrForObjectDetection.from_pretrained(model_name)\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        return processor, model, device\n",
        "    except Exception as e:\n",
        "        st.error(f\"モデルの読み込みに失敗しました: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "def detect_objects(processor, model, device, image, confidence_threshold=0.5):\n",
        "    \"\"\"画像から物体を検出\"\"\"\n",
        "    try:\n",
        "        if isinstance(image, np.ndarray):\n",
        "            image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        else:\n",
        "            image_pil = image\n",
        "\n",
        "        inputs = processor(images=image_pil, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        target_sizes = torch.tensor([image_pil.size[::-1]])\n",
        "        results = processor.post_process_object_detection(\n",
        "            outputs, target_sizes=target_sizes, threshold=confidence_threshold\n",
        "        )[0]\n",
        "\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        st.error(f\"物体検出エラー: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def draw_detections(image, results, model):\n",
        "    \"\"\"検出結果を画像に描画\"\"\"\n",
        "    if isinstance(image, Image.Image):\n",
        "        image = np.array(image)\n",
        "\n",
        "    image_with_boxes = image.copy()\n",
        "    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),\n",
        "              (255, 0, 255), (0, 255, 255), (128, 0, 0), (0, 128, 0)]\n",
        "\n",
        "    for idx, (score, label, box) in enumerate(zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"])):\n",
        "        box = [int(i) for i in box.tolist()]\n",
        "        class_name = model.config.id2label[label.item()]\n",
        "        color = colors[label.item() % len(colors)]\n",
        "\n",
        "        cv2.rectangle(image_with_boxes, (box[0], box[1]), (box[2], box[3]), color, 3)\n",
        "\n",
        "        label_text = f\"{class_name}: {score:.2f}\"\n",
        "        label_size, _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
        "        label_y = box[1] - 10 if box[1] - 10 > 10 else box[1] + label_size[1] + 10\n",
        "\n",
        "        cv2.rectangle(\n",
        "            image_with_boxes,\n",
        "            (box[0], label_y - label_size[1] - 5),\n",
        "            (box[0] + label_size[0], label_y + 5),\n",
        "            color, -1\n",
        "        )\n",
        "\n",
        "        cv2.putText(\n",
        "            image_with_boxes, label_text,\n",
        "            (box[0], label_y),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.8, (255, 255, 255), 2\n",
        "        )\n",
        "\n",
        "    return image_with_boxes\n",
        "\n",
        "def main():\n",
        "    st.markdown(\"<h1>🎯 Object Detection App</h1>\", unsafe_allow_html=True)\n",
        "    st.markdown(\"<p style='text-align: center; color: #666;'>DETR (Detection Transformer) を使用した物体検知システム</p>\", unsafe_allow_html=True)\n",
        "\n",
        "    # サイドバー\n",
        "    with st.sidebar:\n",
        "        st.markdown(\"## ⚙️ 設定\")\n",
        "\n",
        "        model_options = {\n",
        "            \"DETR ResNet-50\": \"facebook/detr-resnet-50\",\n",
        "            \"DETR ResNet-101\": \"facebook/detr-resnet-101\",\n",
        "        }\n",
        "        selected_model = st.selectbox(\"モデルを選択\", options=list(model_options.keys()))\n",
        "\n",
        "        confidence_threshold = st.slider(\n",
        "            \"信頼度閾値\", min_value=0.1, max_value=1.0, value=0.5, step=0.05\n",
        "        )\n",
        "\n",
        "        st.markdown(\"### 🎬 動画処理設定\")\n",
        "        max_frames = st.number_input(\n",
        "            \"処理する最大フレーム数\", min_value=1, max_value=100, value=30\n",
        "        )\n",
        "\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        st.info(f\"実行デバイス: {device.upper()}\")\n",
        "\n",
        "    # メインコンテンツ\n",
        "    tabs = st.tabs([\"📷 画像処理\", \"🎬 動画処理\", \"📊 処理結果\"])\n",
        "\n",
        "    # 画像処理タブ\n",
        "    with tabs[0]:\n",
        "        st.markdown(\"## 📷 画像ファイルのアップロード\")\n",
        "\n",
        "        uploaded_images = st.file_uploader(\n",
        "            \"画像ファイルを選択してください\",\n",
        "            type=['png', 'jpg', 'jpeg', 'bmp', 'tiff'],\n",
        "            accept_multiple_files=True\n",
        "        )\n",
        "\n",
        "        if uploaded_images:\n",
        "            st.markdown(f\"### 📁 アップロードされたファイル: {len(uploaded_images)}個\")\n",
        "\n",
        "            selected_images = []\n",
        "            cols = st.columns(3)\n",
        "            for idx, uploaded_file in enumerate(uploaded_images):\n",
        "                with cols[idx % 3]:\n",
        "                    image = Image.open(uploaded_file)\n",
        "                    st.image(image, caption=uploaded_file.name, use_column_width=True)\n",
        "                    if st.checkbox(f\"処理する\", key=f\"img_{idx}\"):\n",
        "                        selected_images.append((uploaded_file, image))\n",
        "\n",
        "            if st.button(\"🚀 選択した画像を処理\", type=\"primary\"):\n",
        "                if not selected_images:\n",
        "                    st.warning(\"処理する画像を選択してください\")\n",
        "                else:\n",
        "                    # モデルの読み込み\n",
        "                    with st.spinner(\"モデルを読み込んでいます...\"):\n",
        "                        processor, model, device = load_detector(model_options[selected_model])\n",
        "\n",
        "                    if model is None:\n",
        "                        return\n",
        "\n",
        "                    # 画像処理\n",
        "                    st.markdown(\"### 🔄 処理中...\")\n",
        "                    progress_bar = st.progress(0)\n",
        "\n",
        "                    processed_results = []\n",
        "                    for idx, (file, image) in enumerate(selected_images):\n",
        "                        st.text(f\"処理中: {file.name}\")\n",
        "                        image_np = np.array(image)\n",
        "\n",
        "                        results = detect_objects(processor, model, device, image_np, confidence_threshold)\n",
        "                        if results is not None:\n",
        "                            processed_img = draw_detections(image_np, results, model)\n",
        "\n",
        "                            detections = []\n",
        "                            for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "                                class_name = model.config.id2label[label.item()]\n",
        "                                detections.append({\n",
        "                                    'class': class_name,\n",
        "                                    'confidence': float(score),\n",
        "                                    'box': [int(i) for i in box.tolist()]\n",
        "                                })\n",
        "\n",
        "                            processed_results.append({\n",
        "                                'name': file.name,\n",
        "                                'original': image_np,\n",
        "                                'processed': processed_img,\n",
        "                                'detections': detections\n",
        "                            })\n",
        "\n",
        "                        progress_bar.progress((idx + 1) / len(selected_images))\n",
        "\n",
        "                    st.session_state.processed_images = processed_results\n",
        "                    st.success(f\"✅ {len(processed_results)}個の画像処理が完了しました\")\n",
        "\n",
        "    # 動画処理タブ\n",
        "    with tabs[1]:\n",
        "        st.markdown(\"## 🎬 動画ファイルのアップロード\")\n",
        "\n",
        "        uploaded_videos = st.file_uploader(\n",
        "            \"動画ファイルを選択してください\",\n",
        "            type=['mp4', 'avi', 'mov', 'mkv'],\n",
        "            accept_multiple_files=True\n",
        "        )\n",
        "\n",
        "        if uploaded_videos:\n",
        "            st.markdown(f\"### 📁 アップロードされたファイル: {len(uploaded_videos)}個\")\n",
        "\n",
        "            selected_videos = []\n",
        "            for idx, uploaded_file in enumerate(uploaded_videos):\n",
        "                col1, col2 = st.columns([3, 1])\n",
        "                with col1:\n",
        "                    st.text(f\"📹 {uploaded_file.name}\")\n",
        "                with col2:\n",
        "                    if st.checkbox(f\"処理する\", key=f\"vid_{idx}\"):\n",
        "                        selected_videos.append(uploaded_file)\n",
        "\n",
        "            if st.button(\"🚀 選択した動画を処理\", type=\"primary\", key=\"process_videos\"):\n",
        "                if not selected_videos:\n",
        "                    st.warning(\"処理する動画を選択してください\")\n",
        "                else:\n",
        "                    # モデルの読み込み\n",
        "                    with st.spinner(\"モデルを読み込んでいます...\"):\n",
        "                        processor, model, device = load_detector(model_options[selected_model])\n",
        "\n",
        "                    if model is None:\n",
        "                        return\n",
        "\n",
        "                    # 動画処理\n",
        "                    st.markdown(\"### 🔄 処理中...\")\n",
        "\n",
        "                    processed_results = []\n",
        "                    for video_file in selected_videos:\n",
        "                        st.text(f\"処理中: {video_file.name}\")\n",
        "\n",
        "                        # 一時ファイルに保存\n",
        "                        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:\n",
        "                            tmp_file.write(video_file.read())\n",
        "                            tmp_path = tmp_file.name\n",
        "\n",
        "                        # 動画処理\n",
        "                        cap = cv2.VideoCapture(tmp_path)\n",
        "                        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "                        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "                        frames_to_process = min(max_frames, total_frames)\n",
        "                        processed_frames = []\n",
        "                        frame_detections = []\n",
        "\n",
        "                        progress_bar = st.progress(0)\n",
        "                        for i in range(frames_to_process):\n",
        "                            ret, frame = cap.read()\n",
        "                            if not ret:\n",
        "                                break\n",
        "\n",
        "                            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                            results = detect_objects(processor, model, device, frame_rgb, confidence_threshold)\n",
        "\n",
        "                            if results is not None:\n",
        "                                frame_with_boxes = draw_detections(frame_rgb, results, model)\n",
        "                                processed_frames.append(frame_with_boxes)\n",
        "\n",
        "                                detections = []\n",
        "                                for score, label in zip(results[\"scores\"], results[\"labels\"]):\n",
        "                                    class_name = model.config.id2label[label.item()]\n",
        "                                    detections.append({\n",
        "                                        'class': class_name,\n",
        "                                        'confidence': float(score),\n",
        "                                        'frame': i\n",
        "                                    })\n",
        "                                frame_detections.append(detections)\n",
        "\n",
        "                            progress_bar.progress((i + 1) / frames_to_process)\n",
        "\n",
        "                        cap.release()\n",
        "                        os.unlink(tmp_path)\n",
        "\n",
        "                        if processed_frames:\n",
        "                            processed_results.append({\n",
        "                                'name': video_file.name,\n",
        "                                'frames': processed_frames,\n",
        "                                'detections': frame_detections,\n",
        "                                'fps': fps\n",
        "                            })\n",
        "\n",
        "                    st.session_state.processed_videos = processed_results\n",
        "                    st.success(f\"✅ {len(processed_results)}個の動画処理が完了しました\")\n",
        "\n",
        "    # 処理結果タブ\n",
        "    with tabs[2]:\n",
        "        st.markdown(\"## 📊 処理結果\")\n",
        "\n",
        "        # 画像の結果表示\n",
        "        if st.session_state.processed_images:\n",
        "            st.markdown(\"### 🖼️ 画像処理結果\")\n",
        "\n",
        "            for result in st.session_state.processed_images:\n",
        "                st.markdown(f\"#### 📄 {result['name']}\")\n",
        "\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.markdown(\"**オリジナル画像**\")\n",
        "                    st.image(result['original'], use_column_width=True)\n",
        "\n",
        "                with col2:\n",
        "                    st.markdown(\"**検出結果**\")\n",
        "                    st.image(result['processed'], use_column_width=True)\n",
        "\n",
        "                if result['detections']:\n",
        "                    with st.expander(\"🔍 検出されたオブジェクトの詳細\"):\n",
        "                        for det in result['detections']:\n",
        "                            st.write(f\"- **{det['class']}** (信頼度: {det['confidence']:.2%})\")\n",
        "                else:\n",
        "                    st.info(\"オブジェクトが検出されませんでした\")\n",
        "\n",
        "                st.markdown(\"---\")\n",
        "\n",
        "        # 動画の結果表示\n",
        "        if st.session_state.processed_videos:\n",
        "            st.markdown(\"### 🎬 動画処理結果\")\n",
        "\n",
        "            for result in st.session_state.processed_videos:\n",
        "                st.markdown(f\"#### 📹 {result['name']}\")\n",
        "                st.info(f\"FPS: {result['fps']}, 処理フレーム数: {len(result['frames'])}\")\n",
        "\n",
        "                frame_idx = st.slider(\n",
        "                    \"表示するフレーム\", 0, len(result['frames']) - 1, 0,\n",
        "                    key=f\"slider_{result['name']}\"\n",
        "                )\n",
        "\n",
        "                st.image(result['frames'][frame_idx], use_column_width=True)\n",
        "\n",
        "                if result['detections'][frame_idx]:\n",
        "                    with st.expander(\"🔍 このフレームの検出オブジェクト\"):\n",
        "                        for det in result['detections'][frame_idx]:\n",
        "                            st.write(f\"- **{det['class']}** (信頼度: {det['confidence']:.2%})\")\n",
        "\n",
        "                st.markdown(\"---\")\n",
        "\n",
        "        if not st.session_state.processed_images and not st.session_state.processed_videos:\n",
        "            st.info(\"まだ処理された結果がありません。\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "# アプリケーションファイルを保存\n",
        "with open('streamlit_app.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"✅ アプリケーションファイルが作成されました: streamlit_app.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBuZlNdiZx85",
        "outputId": "33a08c7e-0b8f-47f5-91e7-8232ee0626df"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 アプリケーションファイルを作成しています...\n",
            "✅ アプリケーションファイルが作成されました: streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0554c5f"
      },
      "source": [
        "# Install pyngrok\n",
        "!pip install -q pyngrok"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ステップ3: Streamlitの実行方法を表示\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🚀 Streamlitアプリの実行方法\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "以下のいずれかの方法でアプリを実行してください：\n",
        "\n",
        "### 方法1: ローカルURL（推奨）\n",
        "次のセルで以下を実行:\n",
        "!streamlit run streamlit_app.py --server.port 8501 --server.address localhost\n",
        "\n",
        "その後、表示されるローカルURLにアクセス\n",
        "\"\"\")\n",
        "\n",
        "print(\"\"\"\n",
        "### 方法2: ngrokを使用（外部アクセス可能）\n",
        "# ================================================\n",
        "# Streamlit物体検知アプリ用 ngrok設定\n",
        "# ================================================\n",
        "# 1. pyngrokのインストール\n",
        "\"\"\")\n",
        "print(\"!pip install -q pyngrok\") # Print the install command as a separate line\n",
        "\n",
        "print(\"\"\"\n",
        "# 2. ngrokとStreamlitの起動\n",
        "\"\"\")\n",
        "\n",
        "# The actual ngrok setup code should be here or in a separate cell,\n",
        "# not inside a printed multi-line string that represents instructions.\n",
        "# I will move the relevant code outside this print block.\n",
        "\n",
        "print('''\n",
        "以下のコマンドを別々のセルで実行することもできます:\n",
        "\n",
        "# セル1: Streamlitを起動\n",
        "!streamlit run streamlit_app.py --server.port 8501 &\n",
        "\n",
        "# セル2: ngrokでトンネルを作成\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2zmXKSu9aeYc9fK2c3WloIz30sn_81oUvaMFw3r7eV8zHXJAo\")\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "''')\n",
        "\n",
        "# The actual code to run Streamlit and ngrok should be outside the print statements.\n",
        "# I will add the necessary code for Method 2 below the instructions print out.\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🚀 ngrok経由でのStreamlitアプリ起動:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import subprocess\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ngrokの認証トークンを設定（既存のトークンを使用）\n",
        "ngrok.set_auth_token(\"2zmXKSu9aeYc9fK2c3WloIz30sn_81oUvaMFw3r7eV8zHXJAo\")\n",
        "\n",
        "# Streamlitアプリをバックグラウンドで起動\n",
        "# ポート8501（Streamlitのデフォルト）を使用\n",
        "print(\"🚀 Streamlitアプリを起動しています...\")\n",
        "process = subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"streamlit_app.py\", \"--server.port\", \"8501\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "# Streamlitの起動を待つ\n",
        "print(\"⏳ Streamlitの起動を待機中...\")\n",
        "time.sleep(5)\n",
        "\n",
        "# ngrokトンネルを作成（ポート8501に接続）\n",
        "try:\n",
        "    # 既存のトンネルがある場合は閉じる\n",
        "    ngrok.kill()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 新しいトンネルを作成\n",
        "print(\"🌐 ngrokトンネルを作成中...\")\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✅ アプリケーションが起動しました！\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n🔗 公開URL: {public_url}\")\n",
        "print(f\"🔗 ローカルURL: http://localhost:8501\")\n",
        "print(\"\\n上記のURLをクリックしてアプリにアクセスしてください。\")\n",
        "print(\"\\n⚠️  注意事項:\")\n",
        "print(\"- 初回アクセス時はモデルのダウンロードに時間がかかります\")\n",
        "print(\"- セッションを終了する場合は、ランタイムを再起動してください\")\n",
        "\n",
        "# プロセスの状態を確認\n",
        "import psutil\n",
        "import os\n",
        "\n",
        "print(\"\\n📊 実行中のプロセス:\")\n",
        "for proc in psutil.process_iter(['pid', 'name']):\n",
        "    if 'streamlit' in proc.info['name'].lower():\n",
        "        print(f\"- Streamlit (PID: {proc.info['pid']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5nXsPYTZ2sz",
        "outputId": "63cd4322-ebcb-44d4-b23e-8b23aa6c8f3d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "🚀 Streamlitアプリの実行方法\n",
            "============================================================\n",
            "\n",
            "以下のいずれかの方法でアプリを実行してください：\n",
            "\n",
            "### 方法1: ローカルURL（推奨）\n",
            "次のセルで以下を実行:\n",
            "!streamlit run streamlit_app.py --server.port 8501 --server.address localhost\n",
            "\n",
            "その後、表示されるローカルURLにアクセス\n",
            "\n",
            "\n",
            "### 方法2: ngrokを使用（外部アクセス可能）\n",
            "# ================================================\n",
            "# Streamlit物体検知アプリ用 ngrok設定\n",
            "# ================================================\n",
            "# 1. pyngrokのインストール\n",
            "\n",
            "!pip install -q pyngrok\n",
            "\n",
            "# 2. ngrokとStreamlitの起動\n",
            "\n",
            "\n",
            "以下のコマンドを別々のセルで実行することもできます:\n",
            "\n",
            "# セル1: Streamlitを起動\n",
            "!streamlit run streamlit_app.py --server.port 8501 &\n",
            "\n",
            "# セル2: ngrokでトンネルを作成\n",
            "from pyngrok import ngrok\n",
            "ngrok.set_auth_token(\"2zmXKSu9aeYc9fK2c3WloIz30sn_81oUvaMFw3r7eV8zHXJAo\")\n",
            "public_url = ngrok.connect(8501)\n",
            "print(f\"Public URL: {public_url}\")\n",
            "\n",
            "\n",
            "============================================================\n",
            "🚀 ngrok経由でのStreamlitアプリ起動:\n",
            "============================================================\n",
            "🚀 Streamlitアプリを起動しています...\n",
            "⏳ Streamlitの起動を待機中...\n",
            "🌐 ngrokトンネルを作成中...\n",
            "\n",
            "============================================================\n",
            "✅ アプリケーションが起動しました！\n",
            "============================================================\n",
            "\n",
            "🔗 公開URL: NgrokTunnel: \"https://7a9bae3419b8.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "🔗 ローカルURL: http://localhost:8501\n",
            "\n",
            "上記のURLをクリックしてアプリにアクセスしてください。\n",
            "\n",
            "⚠️  注意事項:\n",
            "- 初回アクセス時はモデルのダウンロードに時間がかかります\n",
            "- セッションを終了する場合は、ランタイムを再起動してください\n",
            "\n",
            "📊 実行中のプロセス:\n",
            "- Streamlit (PID: 14186)\n"
          ]
        }
      ]
    }
  ]
}